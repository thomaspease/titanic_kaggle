{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tompease/Documents/Coding/titanic')\n",
    "from utils.data_loader import TitanicLoader\n",
    "from sklearn.model_selection import ShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "from random import uniform\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "loader = TitanicLoader()\n",
    "X, y = loader.load('Survived')\n",
    "\n",
    "cv_split = ShuffleSplit(n_splits = 5, test_size = .3, train_size = .7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regression_param_dist = {\n",
    "  'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "  'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "  'fit_intercept': [True, False],\n",
    "  'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "  'warm_start': [True, False]\n",
    "}\n",
    "\n",
    "random_forest_param_dist = {\n",
    "  'n_estimators': randint(1,1000),\n",
    "  'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "  'min_samples_split': randint(1,20),\n",
    "  'min_samples_leaf': randint(1,20),\n",
    "  'min_weight_fraction_leaf': [0.0, 0.0001, 0.001, 0.1],\n",
    "  'max_features': ['log2', 'sqrt', None],\n",
    "  'bootstrap': [True, False],\n",
    " }\n",
    "\n",
    "decision_tree_param_dist = {\n",
    "  'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "  'splitter' : ['best', 'random'],\n",
    "  'max_depth' : [1, 2, 4, 8, 16, None],\n",
    "  'min_samples_split' : randint(2,10),\n",
    "  'min_samples_leaf' : randint(1, 10),\n",
    "  'min_weight_fraction_leaf': [0.0, 0.0001, 0.001, 0.1],\n",
    "  'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grad_boost_param_dist = {\n",
    "  'loss' : ['log_loss', 'exponential'],\n",
    "  'learning_rate' : [0.001, 0.01, 0.1, 1, 10],\n",
    "  'n_estimators': randint(1,1000),\n",
    "  'min_samples_split': randint(1,10),\n",
    "  'min_samples_leaf': randint(1,20),\n",
    "  'min_weight_fraction_leaf': [0.0, 0.0001, 0.001, 0.1],\n",
    "  'max_depth': randint(1,5),\n",
    "  'max_features': ['sqrt', 'log2', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_algs = [\n",
    "  [LogisticRegression(max_iter=10000), log_regression_param_dist],\n",
    "  [RandomForestClassifier(), random_forest_param_dist],\n",
    "  [DecisionTreeClassifier(), decision_tree_param_dist],\n",
    "  [GradientBoostingClassifier(), grad_boost_param_dist]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "300 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.80447761        nan        nan        nan 0.68656716        nan\n",
      "        nan        nan        nan        nan 0.70597015 0.80820896\n",
      " 0.80895522        nan        nan        nan 0.75671642        nan\n",
      " 0.70597015        nan        nan 0.68955224 0.79477612 0.70597015\n",
      " 0.68955224        nan        nan        nan        nan 0.75373134\n",
      "        nan        nan        nan        nan 0.80522388 0.80671642\n",
      "        nan 0.79029851        nan        nan 0.80671642        nan\n",
      " 0.70597015 0.68880597 0.79029851        nan 0.79477612        nan\n",
      "        nan 0.79029851        nan        nan 0.79626866        nan\n",
      " 0.79477612 0.75597015 0.79179104        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.79701493\n",
      "        nan 0.75671642 0.68656716        nan        nan        nan\n",
      "        nan        nan 0.68656716        nan        nan        nan\n",
      " 0.67089552        nan        nan 0.81044776 0.80746269 0.80597015\n",
      "        nan        nan 0.79850746        nan 0.68656716 0.67089552\n",
      " 0.80671642        nan        nan        nan        nan 0.80447761\n",
      "        nan 0.68432836 0.68656716        nan]\n",
      "  warnings.warn(\n",
      "/Users/tompease/opt/miniconda3/envs/ds-env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.80224719        nan        nan        nan 0.69470305        nan\n",
      "        nan        nan        nan        nan 0.71428571 0.80963082\n",
      " 0.80866774        nan        nan        nan 0.76597111        nan\n",
      " 0.71428571        nan        nan 0.70048154 0.78619583 0.71621188\n",
      " 0.70048154        nan        nan        nan        nan 0.76308186\n",
      "        nan        nan        nan        nan 0.79967897 0.80577849\n",
      "        nan 0.78009631        nan        nan 0.80930979        nan\n",
      " 0.71621188 0.70048154 0.78073836        nan 0.78491172        nan\n",
      "        nan 0.78009631        nan        nan 0.78683788        nan\n",
      " 0.78491172 0.76340289 0.78202247        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.78844302\n",
      "        nan 0.76597111 0.69470305        nan        nan        nan\n",
      "        nan        nan 0.69470305        nan        nan        nan\n",
      " 0.67223114        nan        nan 0.80738363 0.8105939  0.7964687\n",
      "        nan        nan 0.78459069        nan 0.69470305 0.67287319\n",
      " 0.80963082        nan        nan        nan        nan 0.79967897\n",
      "        nan 0.69213483 0.69502408        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ITERATIONS = 100\n",
    "\n",
    "columns = ['MLA name', 'Parameters', 'Train accuracy', 'Test accuracy']\n",
    "MLA_compare = pd.DataFrame(columns = columns)\n",
    "\n",
    "row_index = 0\n",
    "\n",
    "for el in classification_algs:\n",
    "  alg = el[0]\n",
    "  param_grid = el[1]\n",
    "  \n",
    "  name = alg.__class__.__name__\n",
    "  MLA_compare.loc[row_index, 'MLA name'] = name\n",
    "\n",
    "  tuned_model = RandomizedSearchCV(alg, param_distributions=param_grid, n_iter=ITERATIONS, scoring='accuracy', cv=cv_split, return_train_score=True)\n",
    "  tuned_model.fit(X,y)\n",
    "\n",
    "  MLA_compare.loc[row_index, 'Parameters'] = str(tuned_model.best_params_)\n",
    "  MLA_compare.loc[row_index, 'Train accuracy'] = tuned_model.cv_results_[\"mean_train_score\"][tuned_model.best_index_]\n",
    "  MLA_compare.loc[row_index, 'Test accuracy'] = tuned_model.cv_results_[\"mean_test_score\"][tuned_model.best_index_]\n",
    "\n",
    "  row_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 2, 'max_features': None, 'min_samples_leaf': 19, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 925}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_compare.sort_values(by = ['Test accuracy'], ascending = False, inplace = True)\n",
    "\n",
    "MLA_compare.loc[3, 'Parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'log_loss', 'm...</td>\n",
       "      <td>0.866453</td>\n",
       "      <td>0.83209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>0.8687</td>\n",
       "      <td>0.826119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 16, 'max_fe...</td>\n",
       "      <td>0.858427</td>\n",
       "      <td>0.818657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'warm_start': True, 'solver': 'liblinear', 'p...</td>\n",
       "      <td>0.807384</td>\n",
       "      <td>0.810448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MLA name  \\\n",
       "3  GradientBoostingClassifier   \n",
       "1      RandomForestClassifier   \n",
       "2      DecisionTreeClassifier   \n",
       "0          LogisticRegression   \n",
       "\n",
       "                                          Parameters Train accuracy  \\\n",
       "3  {'learning_rate': 0.01, 'loss': 'log_loss', 'm...       0.866453   \n",
       "1  {'bootstrap': True, 'criterion': 'gini', 'max_...         0.8687   \n",
       "2  {'criterion': 'gini', 'max_depth': 16, 'max_fe...       0.858427   \n",
       "0  {'warm_start': True, 'solver': 'liblinear', 'p...       0.807384   \n",
       "\n",
       "  Test accuracy  \n",
       "3       0.83209  \n",
       "1      0.826119  \n",
       "2      0.818657  \n",
       "0      0.810448  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:08:27) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "528eaf8525cf343a920c15b29059300b3605b13ef357b40927062a8441ce532e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
